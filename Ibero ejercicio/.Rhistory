wis_data<-read.csv(file.choose(),stringsAsFactors=FALSE)
wis_data[1]
wis_data<-wis_data[-1]
#semilla numeros aleatorios
set.seed(500)
train_sample<-sample(569,400)
srt(train_sample)
q()
hi
hi=23
hi
#para ejercicio de paises en R copiar código
data_paises<-read.csv(file.choose(),stringsAsFactors=FALSE)
library(C50)
library(class)
modelo_paises<-C5.0(data_paises[,c(2:10)],factor(data_paises$Assignments))
plot(modelo_paises)
summary(modelo_paises)
plot(modelo_paises)
data_examen<-read.csv(file.choose(),stringsAsFactors=FALSE)
summary(data_examen)
sum(data_examen)
tail(data_examen)
summary(data_examen)
tail(data_examen)
#cargamos el archivo
data_examen<-read.csv(file.choose(),stringsAsFactors=FALSE)
print(data_examen)
data_avocado<-read.csv(file.choose(),stringsAsFactors=FALSE)
data_avocado$AveragePrice
mean(data_avocado$AveragePrice)
mean(datos_columna_precio)
datos_columna_precio<-data_avocado$AveragePrice #extraer un acolimna
mean(datos_columna_precio)
hist(datos_columna_precio)
plot(datos_columna_precio)
boxplot(datos_columna_precio)
plot(datos_columna_precio,type="l")
plot(y=datos_columna_precio, x=data_avocado$Total.Volume )
table(c(1,1,1,1,1,1,2,2,2,2,3,3,3,34))
table(data_avocado$year)
table(data_avocado$region)
#definir categorias
cut(datos_columna_precio,breaks=2)
tabla_categorias<-cut(datos_columna_precio,breaks=2)
table(tabla_categorias)
v1<-c(1,5,10,15)
V2<-c(100,500,600,1500)
(v1s<-as.vector(scale(v1)))
(v1s<-as.vector(scale(v2)))
v1<-c(1,5,10,15)
V2<-c(100,500,600,1500)
(v1s<-as.vector(scale(V1)))
(v1s<-as.vector(scale(V2)))
v1<-c(1,5,10,15)
V2<-c(100,500,600,1500)
(v1s<-as.vector(scale(V1)))
(v1s<-as.vector(scale(V2)))
V1<-c(1,5,10,15)
V2<-c(100,500,600,1500)
(v1s<-as.vector(scale(V1)))
(v1s<-as.vector(scale(V2)))
getwd()
#cargamos el archivo
data_avocado<-read.csv(file.choose(),stringsAsFactors=FALSE)
data_columna_fecha
print(data_columna_fecha)
data_avocado
data_columna_fecha<-data_avocado$Date
data_columna_fecha
?split
strsplit(data_columna_fecha, "/")
separadas<-strsplit(data_columna_fecha, "/")
separadas
separadas<-strsplit(data_columna_fecha, "-")
separadas
View(separadas)
View(data_avocado)
data_avocado$dia<-separadas[1]
View(data_avocado)
data_avocado$dia<-separadas[1,2]
data_avocado$dia<-separadas[1,[2]]
data_avocado$dia<-separadas[1]
i<-4
while(i>0){
print("interaccion",i)
i=i-i
}
i<-4
while(i>0){
print("interaccion",i)
i=i-i
}
i<-4
while(i>0){
print("interaccion",i)
i<-i-i
}
i<-4
while(i>=0){
print("interaccion",i)
i<-i-i
}
source('~/.active-rstudio-document', echo=TRUE)
5.7<-bbb
class(bbb)
5<-bbb
class(bbb)
5<-d
class(d)
class(5)
class(5.4)
r<-6
class(5.4)
<-R
class(R)
r<-6
class(r)
r<-c(F,2)
class(r)
r<-c(F,"a")
class(r)
r
print(r)
ID<-c(1,2,3,4)
Edad<-(25,34,28,52)
Diabetes<-("tipo1","tipo2","tipo3","tipo4")
df_pacientes<-data.frame(ID,Edad,Diabetes,Estatus)
df_pacientes
ID<-c(1,2,3,4)
Edad<-c(25,34,28,52)
Diabetes<-c("tipo1","tipo2","tipo3","tipo4")
Estatus<-c("pobre","mejorado","Excelente","pobre")
df_pacientes<-data.frame(ID,Edad,Diabetes,Estatus)
df_pacientes
x<-C(1:4)
x
x<-C(1:4)
print(x)
x<-C(1:4)
print(x)
x<-C(1,2,3,4)
print(x)
x<-C(1,2,3,4)
print(x)
x<-C(1,2,3,4)
x
x<-c(1:4)
x
x<-c(1:5)
is.character(x)
getwd()
datos_aguacate<-data.frame(read.csv("avocado.csv"))
summary(datos_aguacate)
names(datos_aguacate)
nombres<-names(datos_aguacate)
nombres
?rname
nombres<-names(datos_aguacate)
y=("1","2","3")
numeros<-stroi(y)
numeros<-as.numeric(y)
y=("1","2","3")
numeros<-as.numeric(y)
numeros
print(numeros)
md(y
mean(y)
y=("1","2","3")
mean(y)
y=("1","2","3")
mean(y)
print(datos_aguacate)
print(datos_aguacate$region)
datos_aguacate[datos_aguacate$region = "TotalUS", ]
datos_aguacate[datos_aguacate$region == "TotalUS", ]
if  (datos_aguacate$region == "TotalUS"){
file.remove()
}
unique(datos_aguacate$region)
if  (datos_aguacate$region == "Albany"){
file.remove()
}
unique(datos_aguacate$region)
unique(datos_aguacate$region)
datos_aguacate
datos_aguacate$region
if  (datos_aguacate$region == "Albany"){
file.remove(datos_aguacate$region == "Albany")
}
unique(datos_aguacate$region)
datos_aguacate$region
if  (datos_aguacate$region == "Albany"){
file.remove(datos_aguacate$region == "Albany")
}
if  (datos_aguacate$region == "TotalUS"){
file.remove()
}
if  (datos_aguacate$region == "TotalUS"){
file.remove("avocado.csv")
}
library("dplyr", lib.loc="~/R/win-library/3.6")
dplyr
df<-data.frame(color=c("blue","black","blue","blue","black"),
value=1:5)
df
#visualizar el archivo
tbl_df(df)
df<-tbl_df(df)
df
df<-data.frame(color=c("blue","black","blue","blue","black"),
value=1:5)
df
#visualizar el archivo
da<-tbl_df(df)
da
print(da)
df<-data.frame(color=c("blue","black","blue","blue","black"),
value=1:5)
df
filter(df,color=="blue",value==1)
install.packages("dplyr")
library(dplyr)
df<-data.frame(color=c("blue","dark","blue","dark","blue"),
value=1:5
)
df
filter(df,color=="blue")
filter(df,color=="dark")
library("bitops", lib.loc="~/R/win-library/3.6")
detach("package:bitops", unload=TRUE)
df<-tbl_df(df)
df
df
#proceso de modelación lineal
edad<-c(1,3,5,2,11,9,3,9,12,3)
peso<-c(4.4,5.3,7.2,5.2,8.5,7.3,6,10.4,10.2,6.1)
mean(edad)
mean(peso)
plot(edad,peso)
cor(edad,peso)
lm(peso~edad)
datos<-read.csv("insurance.csv")
datos<-read.csv("insurance.csv")
summary(datos)
getwd()
datos<-read.csv("insurance.csv")
summary(datos)
datos<-read.csv("insurance.csv")
summary(datos)
datos<-read.csv("insurance.csv")
datos<-read.csv("insurance.csv")
getwd()
datos<-read.csv("insurance.csv")
summary(datos)
glimpse(insurance)
library(dplyr)
glimpse(insurance)
glimpse(insurance.csv)
glimpse(insurance)
datos
glimpse(datos)
#arbol de regresion
install.packages("rpart")
library(rpart)
?rpart
datos<-read.csv("insurance.csv")
sample(x=1338,size=1338*0.7)
set.seed(733)
sample(x=1338,size=1338*0.7)
set.seed(733)
sample(x=1338,size=1338*0.7)
set.seed(733)
sample_index<- sample(x=1338,size=1338*0.7) #posiciones a muestrear
datos[sample_index,]#set entrenamiento
set.seed(733)
sample_index<- sample(x=1338,size=1338*0.7) #posiciones a muestrear
datos_enternamiento<-datos[sample_index,]#set entrenamiento
rpart(expenses~.)
rpart(expenses~.data=datos_enternamiento)
modelo_entrenaod<-rpart(expenses~.,data=datos_enternamiento)
plot(modelo_entrenaod)
datos<-read.csv("insurance.csv")
#particonar el dataset
set.seed(733)
sample_index<- sample(x=1338,size=1338*0.7) #posiciones a muestrear
datos_enternamiento<-datos[sample_index,]#set entrenamiento
#entrenar el modelo l avariable y es gatos
modelo_entrenaod<-rpart(expenses~.,data=datos_enternamiento)
plot(modelo_entrenaod)
datos<-read.csv("insurance.csv")
#particonar el dataset
set.seed(733)
sample_index<- sample(x=1338,size=1338*0.7) #posiciones a muestrear
datos_enternamiento<-datos[sample_index,]#set entrenamiento
text(modelo_entrenaod)
install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(modelo_entrenaod,digits=4,type=3)
modelo_entrenaod<-rpart(expenses~.,data=datos_enternamiento)
modelo_entrenaod
y_fit<-predict(modelo_entrenaod, datos_enternamiento)
y_real<-datos_enternamiento$expenses
plot(y_real,y_fit)
set.seed(100)
sample_index<- sample(x=1338,size=1338*0.7) #posiciones a muestrear
datos_enternamiento<-datos[sample_index,]#set entrenamiento
#entrenar el modelo l avariable y es gatos
modelo_entrenaod<-rpart(expenses~.,data=datos_enternamiento)
plot(modelo_entrenaod)
text(modelo_entrenaod)
#otro grafico
install.packages("rpart.plot")
library(rpart.plot)
rpart.plot(modelo_entrenaod,digits=4,type=3)
#metricas de desempeño
#AJustes
y_fit<-predict(modelo_entrenaod, datos_enternamiento)
y_real<-datos_enternamiento$expenses
plot(y_real,y_fit)
install.packages("rpart.plot")
edad<-c(1,3,5,2,11,9,3,9,12,3)
peso<-c(4.4,5.3,7.2,5.2,8.5,7.3,6,10.4,10.2,6.1)
mean(edad)
mean(peso)
cor(edad,peso)
plot(edad,peso)
abline(lm(peso~edad))
lm(peso~edad)
install.packages("ISRL")
install.packages(ISRL)
install.packages("ISRL")
names(Hitters)
install.packages("ISRL")
library(ISRL)
data("Hitters")
names(Hitters)
fix(Hitters)
install.packages("ISRL")
library(ISRL)
data("Hitters")
names(Hitters)
___________________
# Otro ejemplo
# AMLO_tweets <- searchTwitter("AMLO", n=100, lang="es", resultType="recent")
# AMLO_tweets
# str(AMLO_tweets)
# Text Mining with R
# install.packages ("twitteR")
# install.packages ("RCurl")
# install.packages ("tm")
# install.packages ("wordcloud")
# install.packages ("stopwords")
# install.packages ("stringi")
# install.packages("sentimentr")
# install.packages("stringr")
# _____________________________
# install.packages ("pattern.nlp")
# install.packages ("mscstexta4r")
# install.packages ("plyr")
# ________________________________
# Packages required for Twitter mining
require (twitteR)
require (RCurl)
require(tm)
require(wordcloud)
require(stopwords)
require(stringi)
require(sentimentr)
require(stringr)
setwd("C:/Users/valde/Documents/tallericaepp")
# Sentiment analysis
file.choose()
# Do not forget specify de R work directory ir order to read the corpus file properly
folder <- "C:/Users/valde/Documents/tallericaepp"
list.files(path=folder)
list.files(path=folder, pattern="*.txt")
# Capture your txt book here
filelist <- list.files(path=folder, pattern="trumpbook.txt")
filelist
typeof(filelist)
lapply(filelist, FUN=readLines)
corpus2 <- lapply(filelist, FUN=readLines)
lapply (corpus2, FUN=paste, collapse="")
corpus2 <- lapply (corpus2, FUN=paste, collapse="")
# Cleaning document
gsub(patter="\\W", replace=" ", corpus2)
corpus3 <- gsub(patter="\\W", replace=" ", corpus2)
gsub(pattern="\\d", replace=" ", corpus3)
corpus3 <- gsub(pattern="\\d", replace=" ", corpus3)
tolower(corpus3)
corpus3 <- tolower(corpus3)
removeWords(corpus3, stopwords())
corpus3 <- removeWords(corpus3, stopwords())
gsub(pattern="\\b[A-z]\\b{1}", replace=" ", corpus3)
corpus3 <- gsub(pattern="\\b[A-z]\\b{1}", replace=" ", corpus3)
stripWhitespace(corpus3)
corpus3 <- stripWhitespace(corpus3)
x11()
wordcloud(corpus3, random.order=F, col=rainbow(50))
opinion.lexicon.pos <- scan('positive-words.txt', what='character', comment.char=';')
opinion.lexicon.neg <- scan('negative-words.txt', what='character', comment.char=';')
str_split(corpus3, pattern="\\s+")
BOOK_bag <- str_split(corpus3,pattern="\\s+")
class(BOOK_bag)
BOOK_bag
lapply(BOOK_bag, function(x) {sum(!is.na(match(x,opinion.lexicon.pos)))})
lapply(BOOK_bag, function(x) {sum(!is.na(match(x,opinion.lexicon.neg)))})
#Hacer un cloud de palabras negativas
#wordcloud(opinion.lexicon.neg, random.order=F, col="red")
#Hacer un cloud de palabras positivas
#wordcloud(opinion.lexicon.pos, random.order=F, col="green")
# Sentiment score
# Positive minus Negative words
lapply(BOOK_bag, function(x) {sum(!is.na(match(x,opinion.lexicon.pos))) - sum(!is.na(match(x,opinion.lexicon.neg)))})
score <- lapply(BOOK_bag, function(x) {sum(!is.na(match(x,opinion.lexicon.pos))) - sum(!is.na(match(x,opinion.lexicon.neg)))})
score
# Para múltiples documentos
# mean(score)
# sd(score)
# hist(score)
# ___________________________________
# Otro ejemplo
# AMLO_tweets <- searchTwitter("AMLO", n=100, lang="es", resultType="recent")
# AMLO_tweets
# str(AMLO_tweets)
